# RTX5080 (16GB) ä¼˜åŒ–é…ç½®æŒ‡å—

## ğŸ“Š ä½ çš„é…ç½®

- **GPU**: RTX5080 (16GB VRAM) âš ï¸ æ˜¾å­˜ç´§å¼ 
- **å½“å‰å¯ç”¨**: 14GB (å·²å ç”¨ 2.1GB)
- **å›¾ç‰‡åˆ†è¾¨ç‡**: 160x210ï¼ˆå·²ä¼˜åŒ–ï¼‰
- **è§†é¢‘é•¿åº¦**: 40 å¸§
- **Batch Size**: 12ï¼ˆæ¨èï¼‰
- **æ··åˆç²¾åº¦**: fp16ï¼ˆ**å¿…é¡»**ï¼‰

## âš ï¸ é‡è¦æé†’

16GB æ˜¾å­˜ç›¸å¯¹ç´§å¼ ï¼Œ**å¿…é¡»ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (fp16)**ï¼Œå¦åˆ™å®¹æ˜“å‡ºç°æ˜¾å­˜æº¢å‡ºã€‚

## âœ… å·²æ›´æ–°çš„é…ç½®

```json
{
  "dataset": {
    "image_size": 160,        // âœ… 160x210 åŸç”Ÿå°ºå¯¸
    "num_frames": 40,
  },
  "training": {
    "batch_size": 12,         // âœ… ä» 4 æ”¹ä¸º 12ï¼ˆå®‰å…¨å€¼ï¼‰
    "num_workers": 4,
    "precision": "fp16"       // âœ… å¿…é¡»ä½¿ç”¨æ··åˆç²¾åº¦
  }
}
```

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

| å‚æ•° | åŸé…ç½® | ä¼˜åŒ–å | ä¼˜åŠ¿ |
|------|--------|--------|------|
| å›¾ç‰‡å°ºå¯¸ | 256x256 | 160x210 | âœ… åŸç”Ÿå°ºå¯¸ |
| Batch Size | 4 | 12 | âœ… 3 å€æå‡ |
| æ··åˆç²¾åº¦ | æ—  | fp16 | âœ… çœæ˜¾å­˜ 40% |
| æ˜¾å­˜éœ€æ±‚ | ~18GB | ~9-11GB | âœ… å®‰å…¨ |

## ğŸ¯ ä¸‰ç§é…ç½®æ–¹æ¡ˆ

### æ–¹æ¡ˆ A: ä¿å®ˆé…ç½®ï¼ˆæœ€å®‰å…¨ï¼‰âœ… æ¨è

```python
config = VideoDatasetConfig(
    data_dir="data",
    config_path="configs/config_example.json",
    image_size=160,
)

dataloader = DataLoader(
    dataset,
    batch_size=8,           # å¾ˆä¿å®ˆï¼Œæ˜¾å­˜å ç”¨ ~6-7GB
    num_workers=2,
    pin_memory=True,
)
```

**æ˜¾å­˜å ç”¨**: ~6-7GB (å®‰å…¨è¾¹é™…å¾ˆå¤§)
**é€‚ç”¨**: å¦‚æœç»å¸¸ OOM æˆ–éœ€è¦ç¨³å®šæ€§

### æ–¹æ¡ˆ B: æ¨èé…ç½®ï¼ˆå¹³è¡¡ï¼‰â­

```python
config = VideoDatasetConfig(
    data_dir="data",
    config_path="configs/config_example.json",
    image_size=160,
)

dataloader = DataLoader(
    dataset,
    batch_size=12,          # â­ æ¨èï¼Œæ˜¾å­˜å ç”¨ ~9-11GB
    num_workers=4,
    pin_memory=True,
)
```

**æ˜¾å­˜å ç”¨**: ~9-11GB (å®‰å…¨)
**é€‚ç”¨**: å¤§å¤šæ•°æƒ…å†µï¼Œæ€§èƒ½å’Œç¨³å®šæ€§å¹³è¡¡

### æ–¹æ¡ˆ C: æ¿€è¿›é…ç½®ï¼ˆé«˜æ€§èƒ½ï¼‰âš ï¸

```python
config = VideoDatasetConfig(
    data_dir="data",
    config_path="configs/config_example.json",
    image_size=160,
)

dataloader = DataLoader(
    dataset,
    batch_size=16,          # æ¿€è¿›ï¼Œæ˜¾å­˜å ç”¨ ~13-14GB
    num_workers=4,
    pin_memory=True,
)
```

**æ˜¾å­˜å ç”¨**: ~13-14GB (é£é™©)
**é€‚ç”¨**: åªæœ‰åœ¨å®Œå…¨ç¡®å®šæ˜¾å­˜å……è¶³æ—¶ä½¿ç”¨
**é£é™©**: æ˜“ OOMï¼Œéœ€è¦éå¸¸è°¨æ…

## ğŸ“‹ æ˜¾å­˜ä¼°ç®—è¡¨ (16GB RTX5080)

**å‰æ**: ä½¿ç”¨ fp16 æ··åˆç²¾åº¦è®­ç»ƒ

| num_frames | batch_size | æ˜¾å­˜å ç”¨ | æ¨èåº¦ | é£é™© |
|-----------|-----------|---------|--------|------|
| 30 | 8 | ~6 GB | â­â­â­â­â­ æå®‰å…¨ | æ—  |
| 30 | 12 | ~8 GB | â­â­â­â­ å®‰å…¨ | æ—  |
| 40 | 8 | ~8 GB | â­â­â­â­ å®‰å…¨ | æ—  |
| 40 | 12 | ~10-11 GB | â­â­â­â­ æ¨è | ä½ |
| 40 | 16 | ~13-14 GB | â­â­ æ¿€è¿› | ä¸­ |
| 50 | 8 | ~10 GB | â­â­â­ å¯ç”¨ | ä½ |
| 50 | 12 | ~13-14 GB | â­â­ é£é™© | ä¸­ |
| 60 | 8 | ~12-13 GB | â­â­ é£é™© | ä¸­ |
| 60 | 12 | ~15-16 GB | âŒ å±é™© | é«˜ |

**âš ï¸ è¯´æ˜**: ä¸è¦å°è¯• fp32ï¼Œä¼šç›´æ¥ OOM

## ğŸ”§ å¿…é¡»é…ç½®: æ··åˆç²¾åº¦è®­ç»ƒ

### æ–¹æ³• 1: ä½¿ç”¨ torch.cuda.amp (æ¨è)

```python
import torch
from torch.cuda.amp import autocast, GradScaler

model = YourModel().cuda()
optimizer = torch.optim.Adam(model.parameters())
criterion = torch.nn.CrossEntropyLoss()
scaler = GradScaler()

for batch in dataloader:
    video = batch['video'].cuda()
    
    optimizer.zero_grad()
    
    # å…³é”®: ä½¿ç”¨ autocast è¿›è¡Œæ··åˆç²¾åº¦å‰å‘ä¼ æ’­
    with autocast():
        output = model(video)
        loss = criterion(output, target)
    
    # ç¼©æ”¾åå‘ä¼ æ’­
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
    
    print(f"Loss: {loss.item():.4f}")
```

### æ–¹æ³• 2: ä½¿ç”¨ PyTorch Lightning (æ›´ç®€æ´)

```python
import pytorch_lightning as pl

class VideoModel(pl.LightningModule):
    def __init__(self):
        super().__init__()
        self.model = YourModel()
        self.criterion = torch.nn.CrossEntropyLoss()
    
    def forward(self, x):
        return self.model(x)
    
    def training_step(self, batch, batch_idx):
        video = batch['video']
        output = self(video)
        loss = self.criterion(output, target)
        return loss
    
    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=1e-3)

# è®­ç»ƒ
trainer = pl.Trainer(
    max_epochs=10,
    precision="16-mixed",  # å¯ç”¨æ··åˆç²¾åº¦
    accelerator="gpu",
    devices=1,
)
trainer.fit(model, dataloader)
```

### æ–¹æ³• 3: ä½¿ç”¨ bfloat16 (å¦‚æœ GPU æ”¯æŒ)

```python
# RTX5080 æ”¯æŒ bfloat16ï¼ˆæ¯” fp16 æ›´ç¨³å®šï¼‰
with autocast(dtype=torch.bfloat16):
    output = model(video)
    loss = criterion(output, target)
```

## ğŸ“Š æ˜¾å­˜ç›‘æ§è„šæœ¬

```python
import torch
import psutil
import GPUtil

def print_memory_stats():
    """æ‰“å°è¯¦ç»†çš„æ˜¾å­˜ä½¿ç”¨æƒ…å†µ"""
    
    # PyTorch æ˜¾å­˜
    allocated = torch.cuda.memory_allocated() / 1e9
    reserved = torch.cuda.memory_reserved() / 1e9
    
    # GPU æ€»æ˜¾å­˜
    gpus = GPUtil.getGPUs()
    total_memory = gpus[0].memoryTotal / 1024
    used_memory = gpus[0].memoryUsed / 1024
    free_memory = gpus[0].memoryFree / 1024
    
    print(f"""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘       æ˜¾å­˜ä½¿ç”¨æƒ…å†µç»Ÿè®¡                  â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘ GPU æ€»æ˜¾å­˜:      {total_memory:>8.1f} GB           â•‘
    â•‘ å·²ä½¿ç”¨:          {used_memory:>8.1f} GB           â•‘
    â•‘ å¯ç”¨:            {free_memory:>8.1f} GB           â•‘
    â•‘                                        â•‘
    â•‘ PyTorch åˆ†é…:    {allocated:>8.1f} GB           â•‘
    â•‘ PyTorch é¢„ç•™:    {reserved:>8.1f} GB           â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

# åœ¨è®­ç»ƒå¾ªç¯ä¸­è°ƒç”¨
for epoch in range(10):
    print(f"\n=== Epoch {epoch+1} ===")
    print_memory_stats()
    
    for batch_idx, batch in enumerate(dataloader):
        # ... è®­ç»ƒä»£ç  ...
        
        if batch_idx == 0:
            print_memory_stats()
```

## âš¡ æ˜¾å­˜ä¼˜åŒ–æŠ€å·§

### 1. æ¢¯åº¦ç´¯ç§¯ï¼ˆé€‚ç”¨äºéœ€è¦å¤§ batch ä½†æ˜¾å­˜ä¸è¶³ï¼‰

```python
accumulation_steps = 4

for batch_idx, batch in enumerate(dataloader):
    video = batch['video'].cuda()
    
    with autocast():
        output = model(video)
        loss = criterion(output, target) / accumulation_steps
    
    loss.backward()
    
    if (batch_idx + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

**æ•ˆæœ**: ç›¸å½“äº batch_size=12 æ—¶ï¼Œç›¸å½“äº batch_size=48
**æ˜¾å­˜å ç”¨**: ç›¸åŒï¼ˆè¿˜æ˜¯ ~10-11GBï¼‰

### 2. æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆGradient Checkpointingï¼‰

```python
from torch.utils.checkpoint import checkpoint

def forward_with_checkpoint(model, video):
    return checkpoint(model, video)

for batch in dataloader:
    video = batch['video'].cuda()
    output = forward_with_checkpoint(model, video)
```

**æ•ˆæœ**: èŠ‚çœæ˜¾å­˜ 30-50%
**ä»£ä»·**: è®­ç»ƒé€Ÿåº¦é™ä½ 10-20%

### 3. å¯ç”¨ TF32 ç²¾åº¦ï¼ˆRTX5080 åŸç”Ÿæ”¯æŒï¼‰

```python
import torch
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True
```

**æ•ˆæœ**: åŠ é€Ÿ 20-30%ï¼Œæ˜¾å­˜å ç”¨ä¸å˜

### 4. åŠæ—¶æ¸…ç©ºç¼“å­˜

```python
# æ¯ä¸ª epoch åæ¸…ç©º
torch.cuda.empty_cache()

# æˆ–å®šæœŸæ¸…ç©º
if batch_idx % 100 == 0:
    torch.cuda.empty_cache()
```

## ğŸš¨ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: RuntimeError: CUDA out of memory

**åŸå› **: æ˜¾å­˜æº¢å‡º

**è§£å†³æ­¥éª¤** (æŒ‰é¡ºåºå°è¯•):

```python
# Step 1: é™ä½ batch_size
batch_size = 8  # ä» 12 æ”¹ä¸º 8

# Step 2: å‡å°‘ num_frames
num_frames = 30  # ä» 40 æ”¹ä¸º 30

# Step 3: å¯ç”¨æ¢¯åº¦ç´¯ç§¯
accumulation_steps = 2
# ... å‚è€ƒä¸Šé¢çš„æ¢¯åº¦ç´¯ç§¯ä»£ç  ...

# Step 4: å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
# ... å‚è€ƒä¸Šé¢çš„æ¢¯åº¦æ£€æŸ¥ç‚¹ä»£ç  ...

# Step 5: å¼ºåˆ¶æ¸…ç©ºç¼“å­˜
torch.cuda.empty_cache()
torch.cuda.reset_peak_memory_stats()
```

### é—®é¢˜ 2: è®­ç»ƒé€Ÿåº¦å¾ˆæ…¢

**æ£€æŸ¥æ¸…å•**:

```python
# 1. ç¡®è®¤å¯ç”¨äº†æ··åˆç²¾åº¦
# âœ… åº”è¯¥æœ‰ with autocast():
# âŒ ä¸åº”è¯¥æ˜¯ with autocast(enabled=False):

# 2. æ£€æŸ¥ TF32 æ˜¯å¦å¯ç”¨
print(torch.backends.cuda.matmul.allow_tf32)  # åº”è¯¥æ˜¯ True

# 3. æ£€æŸ¥ pin_memory
# âœ… pin_memory=True
# âŒ pin_memory=False

# 4. æ£€æŸ¥ num_workers
# âœ… é€šå¸¸ 2-4 å°±å¤Ÿäº†
# âŒ ä¸è¦è¶…è¿‡ CPU æ ¸å¿ƒæ•°

# 5. ç›‘æ§ GPU åˆ©ç”¨ç‡
# åº”è¯¥ > 90%
```

### é—®é¢˜ 3: æ˜¾å­˜ç¢ç‰‡åŒ–

**ç—‡çŠ¶**: æ˜¾å­˜å ç”¨å¢åŠ ä½†ä»æœ‰å¯ç”¨æ˜¾å­˜

**è§£å†³æ–¹æ¡ˆ**:

```python
# æ–¹æ¡ˆ A: å®šæœŸæ¸…ç©º
for epoch in range(num_epochs):
    for batch in dataloader:
        # ... è®­ç»ƒ ...
        pass
    
    torch.cuda.empty_cache()  # æ¯ä¸ª epoch åæ¸…ç©º

# æ–¹æ¡ˆ B: ä½¿ç”¨ cudnn ç¡®å®šæ€§
torch.backends.cudnn.deterministic = True

# æ–¹æ¡ˆ C: é‡å¯ Python è¿›ç¨‹
# å¦‚æœæŒç»­æ¶åŒ–ï¼Œé‡å¯è®­ç»ƒè„šæœ¬
```

## ğŸ“ æœ€ä½³å®è·µ

### âœ… åšè¿™äº›

```python
# 1. å§‹ç»ˆå¯ç”¨æ··åˆç²¾åº¦
with autocast():
    output = model(video)
    loss = criterion(output, target)

# 2. ä½¿ç”¨ pin_memory
dataloader = DataLoader(
    dataset,
    pin_memory=True,
)

# 3. ç›‘æ§æ˜¾å­˜
if batch_idx % 10 == 0:
    print_memory_stats()

# 4. å®šæœŸæ¸…ç©ºç¼“å­˜
if epoch % 5 == 0:
    torch.cuda.empty_cache()

# 5. å¯ç”¨ TF32
torch.backends.cuda.matmul.allow_tf32 = True
```

### âŒ é¿å…è¿™äº›

```python
# 1. ä¸è¦å…³é—­æ··åˆç²¾åº¦
# âŒ ä¼šç›´æ¥ OOM
with autocast(enabled=False):
    pass

# 2. ä¸è¦åœ¨ GPU ä¸Šä¿å­˜å¤§é‡ä¸­é—´ç»“æœ
# âŒ æ˜¾å­˜æ³„æ¼
# âœ… åŠæ—¶åˆ é™¤ä¸éœ€è¦çš„å¼ é‡
del intermediate_output

# 3. ä¸è¦è¿‡åº¦è®¾ç½® num_workers
# âŒ > 8 ä¼šåå‘æ•ˆåº”
num_workers = 4  # åˆé€‚çš„å€¼

# 4. ä¸è¦åŒæ—¶è¿è¡Œå…¶ä»– GPU ç¨‹åº
# âŒ ç«äº‰æ˜¾å­˜

# 5. ä¸è¦ä½¿ç”¨ fp32
# âŒ ç›´æ¥ OOM
# âœ… ä½¿ç”¨ fp16 æˆ– bfloat16
```

## ğŸ¯ å¿«é€Ÿå‚è€ƒ

```python
# â­ æ¨èçš„å®Œæ•´é…ç½®ï¼ˆRTX5080 16GBï¼‰

import torch
from torch.utils.data import DataLoader
from torch.cuda.amp import autocast, GradScaler
from video_dataset import VideoDataset, VideoDatasetConfig

# 0. æ˜¾å­˜ä¼˜åŒ–
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True

# 1. é…ç½®
config = VideoDatasetConfig(
    data_dir="data",
    config_path="configs/config_example.json",
    image_size=160,      # âœ… åŸç”Ÿå°ºå¯¸
)

# 2. æ•°æ®é›†
dataset = VideoDataset(config)

# 3. æ•°æ®åŠ è½½å™¨
dataloader = DataLoader(
    dataset,
    batch_size=12,       # âœ… 16GB æ¨èå€¼
    shuffle=True,
    num_workers=4,       # âœ… 4 ä¸ªåŠ è½½çº¿ç¨‹
    pin_memory=True,     # âœ… é”é¡µå†…å­˜
)

# 4. æ··åˆç²¾åº¦è®­ç»ƒå‡†å¤‡
scaler = GradScaler()

# 5. è®­ç»ƒå¾ªç¯
model = YourModel().cuda()
optimizer = torch.optim.Adam(model.parameters())
criterion = torch.nn.CrossEntropyLoss()

for epoch in range(10):
    for batch in dataloader:
        video = batch['video'].cuda()  # (B, C, T, H, W) = (12, 3, 40, 160, 210)
        
        optimizer.zero_grad()
        
        # âœ… å…³é”®: æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
        with autocast():
            output = model(video)
            loss = criterion(output, target)
        
        # âœ… åå‘ä¼ æ’­
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        
        print(f"Loss: {loss.item():.4f}")
```

**å…³é”®æ£€æŸ¥æ¸…å•**:
- [ ] âœ… ä½¿ç”¨äº†æ··åˆç²¾åº¦ (autocast)
- [ ] âœ… Batch size = 12
- [ ] âœ… num_workers = 4
- [ ] âœ… pin_memory = True
- [ ] âœ… image_size = 160
- [ ] âœ… num_frames = 40
- [ ] âœ… å¯ç”¨ TF32

## ğŸ¯ å¿«é€Ÿå‚è€ƒè¡¨

| è®¾ç½®é¡¹ | å€¼ | å¿…é¡»å— | ä¸ºä»€ä¹ˆ |
|------|-----|--------|--------|
| **æ˜¾å­˜å¤§å°** | 16GB | âœ… | RTX5080 å®é™…é…ç½® |
| **æ··åˆç²¾åº¦** | fp16 | âœ… **å¿…é¡»** | ä¸ç”¨ä¼š OOM |
| **Batch Size** | 12 | âœ… | æ˜¾å­˜å ç”¨ ~10GB |
| **num_frames** | 40 | âœ… | æœ€ä¼˜å¹³è¡¡ |
| **å›¾ç‰‡å°ºå¯¸** | 160x210 | âœ… | åŸç”Ÿæ— æŸ |
| **num_workers** | 4 | â­ | æœ€ä¼˜ CPU åˆ©ç”¨ |
| **pin_memory** | True | â­ | åŠ é€Ÿæ•°æ®ä¼ è¾“ |
| **TF32** | True | â­ | åŠ é€Ÿ 20-30% |

## ğŸ”¥ æ€§èƒ½é¢„æœŸ

ä½¿ç”¨æ¨èé…ç½® (batch_size=12, fp16):

- âœ… æ˜¾å­˜å ç”¨: ~9-11 GB (å®‰å…¨)
- âœ… è®­ç»ƒé€Ÿåº¦: ~15-20% å¿«äº fp32
- âœ… ååé‡: ~120-150 samples/sec
- âœ… å†…å­˜èŠ‚çœ: ~40% vs fp32

## ğŸ“ é‡åˆ°é—®é¢˜ï¼Ÿ

1. **æ£€æŸ¥æ˜¾å­˜**: `nvidia-smi`
2. **æ£€æŸ¥é…ç½®**: çœ‹ `configs/config_example.json`
3. **è¿è¡Œæµ‹è¯•**: `python tests/test_dataloader.py`
4. **æŸ¥çœ‹æ–‡æ¡£**: `docs/VIDEO_DATALOADER_README.md`

---

**ç°åœ¨å¯ä»¥å®‰å…¨åœ°ä½¿ç”¨ RTX5080 (16GB) è¿›è¡Œè®­ç»ƒäº†ï¼** ğŸš€

âš ï¸ **è®°ä½: å¿…é¡»ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (fp16)ï¼Œå¦åˆ™ä¼š OOMï¼**

## ğŸ¯ æ¨èå‚æ•°é…ç½®

### ä¿å®ˆé…ç½®ï¼ˆæœ€å®‰å…¨ï¼‰
```python
config = VideoDatasetConfig(
    data_dir="data",
    config_path="configs/config_example.json",
    image_size=160,  # ä¿æŒåŸç”Ÿå°ºå¯¸
)

dataloader = DataLoader(
    dataset,
    batch_size=8,       # ä¿å®ˆï¼Œæ˜¾å­˜ ~6-7GB
    num_workers=4,
    pin_memory=True,
)
```

### æ¨èé…ç½®ï¼ˆå¹³è¡¡ï¼‰â­
```python
config = VideoDatasetConfig(
    data_dir="data",
    config_path="configs/config_example.json",
    image_size=160,
)

dataloader = DataLoader(
    dataset,
    batch_size=12,      # â­ 16GB æ¨èå€¼
    num_workers=4,
    pin_memory=True,
)
```

### æ¿€è¿›é…ç½®ï¼ˆé«˜æ€§èƒ½ï¼‰
```python
config = VideoDatasetConfig(
    data_dir="data",
    config_path="configs/config_example.json",
    image_size=160,
)

dataloader = DataLoader(
    dataset,
    batch_size=16,      # æ¿€è¿›ï¼Œæ˜¾å­˜ ~13-14GBï¼Œæœ‰é£é™©
    num_workers=6,      # æ›´å¤šæ•°æ®åŠ è½½çº¿ç¨‹
    pin_memory=True,
)
```

## ğŸ”§ è®­ç»ƒè„šæœ¬ä¼˜åŒ–å»ºè®®

### 1. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ

```python
from torch.cuda.amp import autocast, GradScaler

# åˆ›å»º GradScaler
scaler = GradScaler()

# è®­ç»ƒå¾ªç¯
for batch in dataloader:
    optimizer.zero_grad()
    
    # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
    with autocast():
        outputs = model(batch['video'])
        loss = criterion(outputs, target)
    
    # ç¼©æ”¾åå‘ä¼ æ’­
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

### 2. å¢åŠ  num_frames ä»¥æå‡æ•ˆæœ

å¦‚æœæ˜¾å­˜ä»æœ‰ä½™é‡ï¼Œå¯å¢åŠ å¸§æ•°ï¼š

```python
config = VideoDatasetConfig(
    data_dir="data",
    config_path="configs/config_example.json",
    image_size=160,
    # num_frames=40,  # é»˜è®¤
    # num_frames=64,  # å¯å°è¯•å¢åŠ åˆ° 64 å¸§
)
```

**æ˜¾å­˜é¢„ä¼°**:
- 40 å¸§: ~12-14 GB
- 64 å¸§: ~18-20 GB
- 80 å¸§: ~23-24 GB (å±é™©è¾¹ç•Œ)

### 3. ç›‘æ§æ˜¾å­˜ä½¿ç”¨

```python
import torch

# æŸ¥çœ‹æ˜¾å­˜ä½¿ç”¨
print(f"æ˜¾å­˜å·²ç”¨: {torch.cuda.memory_allocated() / 1e9:.1f} GB")
print(f"æ˜¾å­˜é¢„ç•™: {torch.cuda.memory_reserved() / 1e9:.1f} GB")

# è®­ç»ƒå¼€å§‹å‰æ¸…ç©ºç¼“å­˜
torch.cuda.empty_cache()
```

### 4. å¤šGPUæ”¯æŒï¼ˆå¦‚æœéœ€è¦ï¼‰

è™½ç„¶åªæœ‰ä¸€ä¸ª5080ï¼Œä½†è„šæœ¬å¯æ”¯æŒå¤šGPUï¼š

```python
if torch.cuda.device_count() > 1:
    model = nn.DataParallel(model)
```

## ğŸ“‹ æ˜¾å­˜ä¼°ç®—è¡¨

åŸºäº RTX5080 (24GB) å’Œ 160x210 å›¾ç‰‡ï¼š

| num_frames | batch_size | dtype | ä¼°è®¡æ˜¾å­˜ | æ¨èåº¦ |
|-----------|-----------|-------|---------|--------|
| 20 | 24 | fp16 | ~7-8 GB | â­â­â­ å®‰å…¨ |
| 40 | 16 | fp16 | ~12-14 GB | â­â­â­â­ æ¨è |
| 40 | 24 | fp16 | ~18-20 GB | â­â­â­ å¯ç”¨ |
| 64 | 16 | fp16 | ~19-21 GB | â­â­ é£é™© |
| 40 | 16 | fp32 | ~20-22 GB | â­ å±é™© |

## âš¡ æ€§èƒ½æç¤º

### âœ… åšè¿™äº›

1. **ä¿æŒåŸç”Ÿåˆ†è¾¨ç‡** (160x210)
   - æ— ç¼©æ”¾æŸè€—
   - æ˜¾å­˜å ç”¨ä½
   - è®­ç»ƒæ•ˆç‡é«˜

2. **ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ**
   - çœæ˜¾å­˜ 30-40%
   - åŠ å¿«è®­ç»ƒ 10-20%
   - ç²¾åº¦æŸå¤±å‡ ä¹æ— æ„ŸçŸ¥

3. **åˆç†è®¾ç½® num_workers**
   - CPU æ ¸å¿ƒæ•°çš„ä¸€åŠé€šå¸¸æ˜¯æœ€ä¼˜å€¼
   - å¤ªå¤šä¼šå ç”¨ç³»ç»Ÿå†…å­˜

4. **å®šæœŸæ¸…ç©ºæ˜¾å­˜**
   ```python
   torch.cuda.empty_cache()
   ```

### âŒ é¿å…è¿™äº›

1. **ä¸è¦å‡çº§åˆ° 256x256**
   - æ˜¾å­˜å ç”¨ä¼šå¢åŠ  2.56 å€
   - æ— ç›Šå¤„ï¼ˆåŸå§‹æ•°æ®å·²æ˜¯ 160x210ï¼‰

2. **ä¸è¦è¿‡åº¦å¢åŠ  batch_size**
   - è¶…è¿‡ 24 ä¼šæœ‰æ˜¾å­˜æº¢å‡ºé£é™©
   - æ¢¯åº¦ç´¯ç§¯æ•ˆæœä¸å€¼å¾—

3. **ä¸è¦ä½¿ç”¨è¿‡å¤š num_workers**
   - è¶…è¿‡ CPU æ ¸å¿ƒæ•°ä¼šåå‘æ•ˆåº”
   - å»ºè®®ä¸è¶…è¿‡ 8

4. **ä¸è¦åŒæ—¶è¿è¡Œå…¶ä»– GPU ç¨‹åº**
   - å…¶ä»–ç¨‹åºä¼šäº‰å¤ºæ˜¾å­˜
   - å¯èƒ½å¯¼è‡´ OOM

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜: æ˜¾å­˜æº¢å‡º (OOM)

**è§£å†³æ–¹æ¡ˆ** (æŒ‰ä¼˜å…ˆçº§):
```python
# 1. é™ä½ batch_size
batch_size = 8  # ä» 16 é™åˆ° 8

# 2. æ¸…ç©ºæ˜¾å­˜ç¼“å­˜
torch.cuda.empty_cache()

# 3. å‡å°‘ num_frames
num_frames = 30  # ä» 40 é™åˆ° 30

# 4. å¯ç”¨æ¢¯åº¦ç´¯ç§¯
for i, batch in enumerate(dataloader):
    outputs = model(batch['video'])
    loss = criterion(outputs, target)
    loss.backward()
    if (i + 1) % 2 == 0:  # æ¯ 2 ä¸ª batch æ›´æ–°ä¸€æ¬¡
        optimizer.step()
        optimizer.zero_grad()
```

### é—®é¢˜: è®­ç»ƒé€Ÿåº¦æ…¢

**æ£€æŸ¥é¡¹ç›®**:
```python
# 1. ç¡®è®¤ä½¿ç”¨äº†æ··åˆç²¾åº¦
with autocast():  # æ·»åŠ è¿™ä¸ª
    outputs = model(batch)

# 2. æ£€æŸ¥ num_workers æ˜¯å¦åˆç†
# å¯å°è¯•ä» 4 å¢åŠ åˆ° 6-8

# 3. æ£€æŸ¥ pin_memory
dataloader = DataLoader(
    dataset,
    pin_memory=True,  # ç¡®ä¿æ‰“å¼€
    num_workers=4,
)
```

## ğŸ“š å¿«é€Ÿå‚è€ƒ

```python
# â­ æ¨èçš„å®Œæ•´é…ç½®

import torch
from torch.utils.data import DataLoader
from video_dataset import VideoDataset, VideoDatasetConfig

# 1. é…ç½®
config = VideoDatasetConfig(
    data_dir="data",
    config_path="configs/config_example.json",
    image_size=160,      # âœ… åŸç”Ÿå°ºå¯¸
)

# 2. æ•°æ®é›†
dataset = VideoDataset(config)

# 3. æ•°æ®åŠ è½½å™¨
dataloader = DataLoader(
    dataset,
    batch_size=16,       # âœ… RTX5080 æ¨è
    shuffle=True,
    num_workers=4,       # âœ… 4 ä¸ªåŠ è½½çº¿ç¨‹
    pin_memory=True,     # âœ… é”é¡µå†…å­˜
)

# 4. æ··åˆç²¾åº¦è®­ç»ƒå‡†å¤‡
from torch.cuda.amp import GradScaler
scaler = GradScaler()

# 5. è®­ç»ƒå¾ªç¯
model = YourModel().cuda()
optimizer = torch.optim.Adam(model.parameters())

for epoch in range(10):
    for batch in dataloader:
        video = batch['video'].cuda()  # (B, C, T, H, W)
        
        optimizer.zero_grad()
        
        # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
        with autocast():
            output = model(video)
            loss = criterion(output, target)
        
        # åå‘ä¼ æ’­
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        
        print(f"Loss: {loss.item():.4f}")
```

## ğŸ‰ æ€»ç»“

| é…ç½®é¡¹ | å€¼ | åŸå›  |
|------|-----|------|
| å›¾ç‰‡å°ºå¯¸ | 160x210 | åŸç”Ÿåˆ†è¾¨ç‡ï¼Œæ— æŸè€— |
| Batch Size | 16 | RTX5080 æœ€ä¼˜å¹³è¡¡ |
| num_frames | 40 | æ˜¾å­˜å……è¶³ï¼Œæ•ˆæœå¥½ |
| æ··åˆç²¾åº¦ | fp16 | èŠ‚çœæ˜¾å­˜ï¼ŒåŠ é€Ÿ |
| num_workers | 4 | CPU æ•ˆç‡æœ€ä¼˜ |

**é¢„æœŸç»“æœ**:
- âœ… æ˜¾å­˜å ç”¨: 12-14 GBï¼ˆå®‰å…¨ï¼‰
- âœ… æ¢¯åº¦ç¨³å®šæ€§: å¥½ï¼ˆbatch_size=16ï¼‰
- âœ… è®­ç»ƒé€Ÿåº¦: å¿«ï¼ˆæ··åˆç²¾åº¦ + ä¼˜åŒ–ï¼‰
- âœ… è®­ç»ƒè´¨é‡: é«˜ï¼ˆå……è¶³çš„è§†é¢‘å¸§ï¼‰

---

**ç°åœ¨å¯ä»¥ç›´æ¥ä½¿ç”¨ä¼˜åŒ–åçš„é…ç½®äº†ï¼** ğŸš€

```bash
python examples/simple_example.py simple
```

æˆ–åœ¨ä»£ç ä¸­ï¼š
```python
config = VideoDatasetConfig(
    data_dir="data",
    config_path="configs/config_example.json",
)
```
